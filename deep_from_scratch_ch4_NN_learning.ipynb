{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_from_scratch_ch4_NN_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3IySmbxqF5Qi4Rr40iza5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinInoue-rrr/from_scratch/blob/main/deep_from_scratch_ch4_NN_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3dEUSbJe0by"
      },
      "source": [
        "# 4章　ニューラルネットワークの学習\n",
        "\n",
        "## 4.1 データから学習する\n",
        "\n",
        "<br />\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2GjXgoKt1x0",
        "outputId": "1c08d566-64c3-486d-f7cf-791284b3da7c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3pF_Ju3luE0H",
        "outputId": "628f5aeb-f7a7-4e82-c1e3-c094454e22ae"
      },
      "source": [
        "import os \n",
        "os.getcwd()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj6IfMhnuJDF"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/deep-learning-from-scratch-master/ch04\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GPTt9Hr9uONN",
        "outputId": "ce66be00-eaa4-4185-9d32-ffa9ce1e7f23"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/deep-learning-from-scratch-master/ch04'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yj4QdRfk4xx"
      },
      "source": [
        "### 4.1.2\n",
        "\n",
        "<br />\n",
        "\n",
        "モデルの汎化能力が重要。汎化能力とは、まだ見ぬデータに対する予測能力のことである。過学習を避けるためにも、訓練データとテストデータをきちんと分けることが重要。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UTLmKyjlT7b"
      },
      "source": [
        "## 4.2 損失関数(loss function) \n",
        "\n",
        "<br />\n",
        "\n",
        "一般には2乗和誤差や、交差エントロピー誤差などが用いられる。\n",
        "\n",
        "### 4.2.1 2乗和誤差\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cp-d1e8n-BK"
      },
      "source": [
        "# 2乗和誤差の実装\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def sum_squared_error(y, t):\n",
        "    return 0.5 * np.sum((y-t)**2)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFtMJO5PoKxC",
        "outputId": "94fbd895-d85c-4210-a7b4-10d985849b5c"
      },
      "source": [
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "sum_squared_error(np.array(y), np.array(t))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09750000000000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPLubmoZovZw"
      },
      "source": [
        " ### 4.2.2 交差エントロピー誤差\n",
        "\n",
        " $E = -\\sum_k t_k log{y_k} ... (4.2)$\n",
        "\n",
        " $t_k$は正解ラベルとなるインデックスだけが1となり、それ以外は0となるone-hot表現\n",
        " 交差エントロピー誤差は、正解ラベルとなる出力の結果によって、その値が決まる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gASj2a3OpMMs"
      },
      "source": [
        "#交差エントロピー誤差の実装\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    delta = 1e-7\n",
        "    return -np.sum(t * np.log(y + delta)) ### deltaは微小な値であり、log(0)となってマイナス無限大の-infとならないようにしている。実装上の理由。"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D1p-HSRrDt_",
        "outputId": "998d3c69-c8c0-432b-ffbb-6ea29ae7be4e"
      },
      "source": [
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.510825457099338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm8QAMRPzf9q"
      },
      "source": [
        "### 4.2.3 ミニバッチ学習\n",
        "\n",
        "<br />\n",
        "\n",
        "$E = -\\frac{1}{N}\\sum_n\\sum_k t_{nk}log{y_{nk}} ... (4.3)$ \n",
        "\n",
        "MNISTでは、訓練データだけで60000もあるため、損失関数の計算も時間がかかる。そのため、全体からサブグループをランダムに抽出して、小規模な学習を行う手法を**ミニバッチ学習**という。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHNU24NhrXpx"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlKjQZH1uhe6"
      },
      "source": [
        "(x_train, t_train), (x_test, t_test) = \\\n",
        "    load_mnist(normalize = True, one_hot_label = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJB-9mvPuvKE",
        "outputId": "9ab2afd1-1e12-44a9-cb11-c093866323b0"
      },
      "source": [
        "print(x_train.ndim)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiBgqw6puyau",
        "outputId": "428d2156-636b-413d-d5f5-2ba27850b916"
      },
      "source": [
        "print(t_train.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAKuXRvsu1X2"
      },
      "source": [
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)#ランダムにインデックスを選び出す\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlrCmgW-2PPc",
        "outputId": "3ae9e737-dfeb-410d-d933-6448491e9578"
      },
      "source": [
        "batch_mask"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22102, 11631, 21433, 51149, 32182, 49734, 27594, 35892, 26402,\n",
              "       13531])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueKPzXnb2Q8H"
      },
      "source": [
        "### 4.2.4 バッチ対応版の交差エントロピー誤差の実装\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnsnR8MG5H_N"
      },
      "source": [
        "#教師データがラベルとして与えられた時の、交差エントロピー誤差の実装\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgyuIfXE7XcC"
      },
      "source": [
        "### 4.2.5 なぜ損失関数を設定するのか？\n",
        "\n",
        "<br />\n",
        "\n",
        "最適なパラメータの探索の際には、損失関数の値ができるだけ小さくなるようなパラメータを探す。パラメータの微分を計算し、その微分の値を手掛かりに値を更新していく。\n",
        "ある一つの重みパラメータの損失関数に関する微分は、その重みパラメータを少しだけ変化させたときに、損失関数がどのように変化するかを表している。しかし、微分が0になってしまうと、どちらの方向にも動かなくなってしまう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcOQAnJM9RJu"
      },
      "source": [
        "## 4.3 \n",
        "\n",
        "### 4.3.1 微分\n",
        "\n",
        "<br />\n",
        "\n",
        "ある瞬間の変化量を指す\n",
        "\n",
        "<br />\n",
        "\n",
        "##### 数値微分(numerical differentiation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYhC8aqr-mma"
      },
      "source": [
        "## 悪い実装例\n",
        "\n",
        "def numerical_diff(f, x):\n",
        "    h = 1e-50#極めて小さい値\n",
        "    return (f(x+h) - f(x) ) / h"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv4bdlBA-2Gn"
      },
      "source": [
        "`1e-50`は極めて小さい値だが、これにより**丸め誤差(rounding error)**の問題が生じる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUbgfusL_KwB",
        "outputId": "d137715e-4714-46a5-ebaf-919ced67b9c4"
      },
      "source": [
        "np.float32(1e-50)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGiDRIK6_Nah"
      },
      "source": [
        "#中心差分をとったマシな実装例\n",
        "\n",
        "def numerical_diff(f, x):\n",
        "    h = 1e-4#これくらいのオーダーで十分らしい\n",
        "    return (f(x+h) - f(x-h)) / 2*h"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kEDWk5jBzei"
      },
      "source": [
        "### 4.3.2 数値微分の例\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdOQLhVnC1pR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "oT-ubVvYC68g",
        "outputId": "a2ea6e9c-c542-4520-8d31-adab060c0020"
      },
      "source": [
        "def function_1(x):\n",
        "    return 0.01 * x **2 + 0.1 * x\n",
        "x = np.arange(0.0, 20.0, 0.1)\n",
        "y = function_1(x)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLY5O207DYnc",
        "outputId": "6532e956-c4e4-4611-e0c8-194b5281f333"
      },
      "source": [
        "numerical_diff(function_1, 5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9999999999908982e-09"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fzX4EGvDhbc",
        "outputId": "76f05339-54e6-46d2-e9a2-db652aa46151"
      },
      "source": [
        "numerical_diff(function_1, 10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.999999999986347e-09"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMrBBjfhDnG5"
      },
      "source": [
        "### 4.3.3 偏微分\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FPJwZveEbTa"
      },
      "source": [
        "def function_2(x):\n",
        "    return x[0] ** 2 + x[1] ** 2#numpy配列の各要素の二乗和を計算するだけ"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n45OcRMnFGIN"
      },
      "source": [
        "## x0 = 3, x1 = 4の時のx0に対する偏微分を求める\n",
        "\n",
        "def function_tmp1(x0):\n",
        "    return x0 * x0 + 4.0 ** 2.0#x1を4で固定して、x0についての関数として定義し直し、このx0について微分する\n",
        "\n",
        "    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quePPsQOFnLE",
        "outputId": "d8245acb-a5b8-49e7-d10c-b54e928fe605"
      },
      "source": [
        "numerical_diff(function_tmp1, 3.0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.000000000003781e-08"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsoFVbqaFrLM"
      },
      "source": [
        "## 4.4 勾配"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "942GEv26GHlm"
      },
      "source": [
        "$\\nabla f = (\\frac{\\partial f}{\\partial x_0}, \\frac{\\partial f}{\\partial x_1})$\n",
        "\n",
        "このように、それぞれの変数による偏微分をまとめたベクトルのことを勾配(gradient)という。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqxpkM7mHN2g"
      },
      "source": [
        "# 勾配の実装\n",
        "\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4#0.0001\n",
        "    grad = np.zeros_like(x)#xと同じ形状の配列を作成し、0で初期化する\n",
        "    #以下のfor loopはインデックス番号と変数の種類が対応している\n",
        "    for idx in range(x.size):#rangeは0からx.size-1の番号まで。\n",
        "        tmp_val = x[idx]#現在の値\n",
        "        #f(x + h)の計算\n",
        "        x[idx] = tmp_val + h#xからidxのインデックスの中身を取り出して、hを足して元に戻しているだけ\n",
        "        fxh1 = f(x)\n",
        "\n",
        "        #f(x - h)の計算\n",
        "        x[idx] = tmp_val - h\n",
        "        fxh2 = f(x)\n",
        "\n",
        "        grad[idx] = (fxh1 - fxh2 ) / (2*h)\n",
        "        x[idx] = tmp_val#元に戻す\n",
        "\n",
        "    return grad"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amld5FGvJUyH",
        "outputId": "f86a9d77-2795-449d-afed-3cb4f1c44c87"
      },
      "source": [
        "numerical_gradient(function_2, np.array([3.0, 4.0]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6., 8.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPvxxrSSKcLU"
      },
      "source": [
        "### 勾配の性質\n",
        "\n",
        "<br />\n",
        "\n",
        "勾配が示す方向は、各地点において関数の値を最も減らす方向を指し示している点が重要\n",
        "\n",
        "つまり、勾配の符号が更新の方向を定めるということ。。。。。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF63dLgXLPK-"
      },
      "source": [
        "### 4.4.1 勾配降下法(gradient descent method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYyWkgqNs-qm"
      },
      "source": [
        "機械学習の問題の多くは、学習の際に最適なパラメータを探索する。NNもまた、同様に重みとバイアスを学習時に見つけなければいけない。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmppH-QDtm7G"
      },
      "source": [
        "### 勾配降下法（gradient descent method）\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zwN4979wrGc"
      },
      "source": [
        "# 勾配降下法の実装\n",
        "\n",
        "def numerical_gradient(f, x):#xはnumpy配列を想定している\n",
        "    h = 1e-4#0.0001\n",
        "    grad = np.zeros_like(x)#xと同じ形状の配列を作成し、0で初期化する\n",
        "    #以下のfor loopはインデックス番号と変数の種類が対応している\n",
        "    for idx in range(x.size):#rangeは0からx.size-1の番号まで。\n",
        "        tmp_val = x[idx]#現在の値\n",
        "        #f(x + h)の計算\n",
        "        x[idx] = tmp_val + h#xからidxのインデックスの中身を取り出して、hを足して元に戻しているだけ\n",
        "        fxh1 = f(x)\n",
        "\n",
        "        #f(x - h)の計算\n",
        "        x[idx] = tmp_val - h\n",
        "        fxh2 = f(x)\n",
        "\n",
        "        grad[idx] = (fxh1 - fxh2 ) / (2*h)\n",
        "        x[idx] = tmp_val#元に戻す\n",
        "\n",
        "    return grad\n",
        "\n",
        "def gradient_descent(f, init_x, lr = 0.01, step_num = 100):  #lr = learning rate:学習率であり、ハイパーパラメータ\n",
        "    x = init_x\n",
        "\n",
        "    for i in range(step_num):\n",
        "        grad = numerical_gradient(f, x)#勾配を生成\n",
        "        x -= lr * grad#ハイパーパラメータと勾配の積を引く\n",
        "\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "  #fは最適化したい関数、init_xは初期値、lrは学習率、step_numは勾配法による繰り返しの回数のこと\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIKZVcyEzQl2"
      },
      "source": [
        "###### この関数を使うことによって、関数の極小値を得ることができる。うまくいけば最小値を求めることもできる\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBkW-wvKzkO0"
      },
      "source": [
        "def function_2(x):\n",
        "    return x[0]**2 + x[1]**2"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T30w9_COz76B"
      },
      "source": [
        "init_x = np.array([-3.0, 4.0])#適当な初期値からスタートして、探索することによって極小値を得ている。"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b875LYwa0N4V",
        "outputId": "77ed2c1d-96b2-4256-902b-73c2b19a0df5"
      },
      "source": [
        "gradient_descent(function_2, init_x = init_x, lr = 0.1, step_num = 100)#実際の最小値は(0, 0)なので、限りなく近い値を獲得することができている。\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.11110793e-10,  8.14814391e-10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugNKxtfs0b0m"
      },
      "source": [
        "#learning rateが大きすぎても、小さすぎてもうまくいかないことの例\n",
        "\n",
        "init_x = np.array([-3.0, 4.0])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7kycN2H1Ec2",
        "outputId": "17ba7ffa-9e5f-459f-c340-e574ff2e3b99"
      },
      "source": [
        "gradient_descent(function_2, init_x = init_x, lr = 10.0, step_num = 100)#学習率が大きすぎると発散してしまう"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.58983747e+13, -1.29524862e+12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYWD3yqQ1cfH"
      },
      "source": [
        "#learning rateが小さすぎるとどうなるか\n",
        "\n",
        "init_x = np.array([-3.0, 4.0])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBF72O5B11PQ",
        "outputId": "6b45c99b-3975-4239-d7c7-d73bdbe4dc30"
      },
      "source": [
        "gradient_descent(function_2, init_x = init_x, lr = 1e-10, step_num = 100)#ほとんど初期値から進まないのでこれだと意味がない"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.99999994,  3.99999992])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPMb44n1-j0",
        "outputId": "8d11fee9-71dd-4529-c0f0-2bbccaf28dfd"
      },
      "source": [
        "#実行回数増やすとどうなるか\n",
        "\n",
        "gradient_descent(function_2, init_x = init_x, lr = 1e-10, step_num = 1000)#10倍程度じゃ変わらないけど、かといって増やしすぎると学習に時間がかかるためバランスがむずかしい。多分普通は交差検証とかで決めるんだと思う。\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.99927121,  3.99916161])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN2jJJ9v2R-A"
      },
      "source": [
        "## 4.4.2 ニューラルネットワークに対する勾配\n",
        "\n",
        "<br />\n",
        "\n",
        "重みパラメータに関する、損失関数の勾配を求める！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg3Splsu3WjW"
      },
      "source": [
        "# importする\n",
        "\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from common.functions import softmax, cross_entropy_error\n",
        "from common.gradient import numerical_gradient"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdS99ebK3rFg"
      },
      "source": [
        "#simpleNet というクラスを実装する\n",
        "\n",
        "class simpleNet:\n",
        "      def __init__(self):\n",
        "          self.W = np.random.randn(2, 3)\n",
        "      \n",
        "      def predict(self, x):\n",
        "          return np.dot(x, self.W)\n",
        "\n",
        "      def loss(self, x, t):\n",
        "            z = self.predict(x)\n",
        "            y = softmax(z)\n",
        "            loss = cross_entropy_error(y, t)\n",
        "\n",
        "            return loss\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z36OJUEv45gJ",
        "outputId": "288a101a-54f3-4965-8253-539a49382fb4"
      },
      "source": [
        "#試しに使ってみる\n",
        "\n",
        "net = simpleNet()\n",
        "print(net.W)#この段階だと、重みパラメータはガウス分布からランダムに生成された初期値が表示されている"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.63142721 -1.26191328 -0.28376783]\n",
            " [-0.15424325 -1.07259063  0.53311632]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_V3O2SH5jQt",
        "outputId": "86041bac-6770-4a19-fed9-f236336c5735"
      },
      "source": [
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)\n",
        "print(p)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.51767525 -1.72247954  0.30954399]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHczWPFT58v8",
        "outputId": "9eb7a3ca-cfcc-4140-d9f8-ee6bc7c155ab"
      },
      "source": [
        "np.argmax(p)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ore_ZB6Jmm",
        "outputId": "bd4da9e0-2604-4736-88dd-16b6cf6ee9b8"
      },
      "source": [
        "t = np.array([0, 0, 1])#正解のラベル\n",
        "net.loss(x, t)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4500134650338166"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3fs-FnD6bIT"
      },
      "source": [
        "#NNの損失関数の勾配を求める\n",
        "\n",
        "def f(W):\n",
        "    return net.loss(x, t)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EjtdnKt7HOD",
        "outputId": "5221da52-33d5-4952-a539-e52b4bd43969"
      },
      "source": [
        "net.W"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.63142721, -1.26191328, -0.28376783],\n",
              "       [-0.15424325, -1.07259063,  0.53311632]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6_huCcj6mCD",
        "outputId": "822eac3e-e2e1-43c6-a071-ad56e881e6c5"
      },
      "source": [
        "dW = numerical_gradient(f, net.W)#NNの損失関数lossについて、net.Wをパラメータの初期値として勾配降下法を用いている \n",
        "\n",
        "print(dW)#これは、例えば、二行三列の重みw23について、w23をhだけ増やすと、損失関数の値は0.32hほど小さくなるため、w23はプラスの方向に小さくした方が良い。\n",
        "#一方で、プラスの値を持っているものついては、反対の方向にパラメータの値を増やすことによって損失関数の値を減少させることができるということ"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.16728461  0.05014367 -0.21742829]\n",
            " [ 0.25092692  0.07521551 -0.32614243]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5d8K8rN7eWQ"
      },
      "source": [
        "## 4.5 学習アルゴリズムの実装\n",
        "\n",
        "<br />\n",
        "\n",
        "ここまで連続して学習が続いたので、ここで一度復習タイムに入る。\n",
        "\n",
        "### 前提\n",
        "\n",
        "<br />\n",
        "\n",
        "NNは重みとバイアスを調整する必要がある。\n",
        "これを訓練データに適応するように調整することを「学習」という。\n",
        "\n",
        "<br />\n",
        "\n",
        "#### 学習のステップ\n",
        "\n",
        "##### ステップ1：ミニバッチ\n",
        "\n",
        "<br />\n",
        "\n",
        "訓練データの中からランダムに一部のデータのグループを選び出す。そこで選ばれたデータのグループのことをミニバッチという。そして、ここではこのミニバッチの値を小さくすることが目的となる。\n",
        "\n",
        "\n",
        "##### ステップ2：勾配の算出\n",
        "\n",
        "<br />\n",
        "\n",
        "ミニバッチの損失関数を減らすために、重みパラメータの勾配を求める。勾配は損失関数の値を最も減らす方向を示している。\n",
        "\n",
        "\n",
        "##### ステップ3：パラメータの更新\n",
        "\n",
        "<br />\n",
        "\n",
        "重みパラメータを勾配方向に微少量デルタだけ更新する\n",
        "\n",
        "\n",
        "#####  ステップ4：繰り返す\n",
        "\n",
        "<br />\n",
        "\n",
        "ステップ1、2、3を繰り返す\n",
        "\n",
        "なお、ここでは使用するデータをミニバッチとして無作為にデータを抽出しているため、確率的勾配降下法(Stochastic Gradient Descent)と呼ばれる。SGD。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Li3Rm8F-FGt"
      },
      "source": [
        "### 4.5.1 二層NNのクラス\n",
        "\n",
        "<br />\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Fyfg1I-qhU"
      },
      "source": [
        "# 2層ニューラルネットワークの実装\n",
        "\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "from common.functions import *\n",
        "from common.gradient import numerical_gradient\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAEnNJtK-9rG"
      },
      "source": [
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, \n",
        "                      weight_init_std = 0.01):\n",
        "          self.params = {}#空っぽのディクショナリとして初期化\n",
        "                                 #paramsは、NNのパラメータを保持するインスタンス変数\n",
        "          self.params[\"W1\"] = weight_init_std * \\\n",
        "                                        np.random.randn(input_size, hidden_size)\n",
        "          self.params[\"b1\"] = np.zeros(hidden_size)\n",
        "          self.params[\"W2\"] = weight_init_std * \\\n",
        "                                        np.random.randn(hidden_size, output_size)\n",
        "          self.params[\"b2\"] = np.zeros(output_size)\n",
        "\n",
        "\n",
        "\n",
        "          # __init__はTwoLayerNetを生成する時に呼ばれるメソッド\n",
        "          # input_sizeは入力層のニューロンの数。今回は784個ある。一つの画像につき28 * 28 = 784個の変数を用いている。\n",
        "          # hidden_sizeは隠れニューロン層の数、output_sizeは出力層のニューロンの数\n",
        "\n",
        "          # 疑問：hidden_sizeは適当なサイズを設定するらしいが、これはハイパーパラメータではないのか？\n",
        "\n",
        "          # そもそもselfが必要なのは、最低限一つ以上の変数がないと動かないからで、慣習的にselfを用いているだけ。\n",
        "          # 例えば variable = TwoLayerNet()として初期化すると、それぞれのメソッドはvariable.method()として記述する\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, x):# 認識、推論を行うメソッド。引数のxは画像データ。MNISTなら。\n",
        "          W1, W2 = self.params[\"W1\"], self.params[\"W2\"]\n",
        "          b1, b2 = self.params[\"b1\"], self.params[\"b2\"]\n",
        "\n",
        "\n",
        "          a1 = np.dot(x, W1) + b1#0層の入力を1層への出力にしている\n",
        "          z1 = sigmoid(a1)#1層の入力を2層への出力にしている\n",
        "          a2 = np.dot(z1, W2) + b2#2層への入力を3層への出力にしている\n",
        "          y = softmax(a2)#最終的な出力をソフトマックス関数にしている\n",
        "\n",
        "          return y\n",
        "\n",
        "\n",
        "    def loss(self, x, t):\n",
        "          y = self.predict(x)\n",
        "        \n",
        "          return cross_entropy_error(y, t)\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "          y = self.predict(x)\n",
        "          y = np.argmax(y, axis = 1)\n",
        "          t = np.argmax(t, axis = 1)\n",
        "\n",
        "          accuracy = np.sum(y ==  t) / float(x.shape[0])\n",
        "          return accuracy\n",
        "    \n",
        "    def numerical_gradient(self, x, t):\n",
        "          loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "          grads = {}#空のディクショナリを作成\n",
        "\n",
        "          #gradsは各層の重みとバイアスそれぞれの勾配を保持するディクショナリ変数であり、numerical_gradient()メソッドの返り値\n",
        "\n",
        "          grads[\"W1\"] = numerical_gradient(loss_W, self.params[\"W1\"])\n",
        "          grads[\"b1\"] = numerical_gradient(loss_W, self.params[\"b1\"])\n",
        "          grads[\"W2\"] = numerical_gradient(loss_W, self.params[\"W2\"])\n",
        "          grads[\"b2\"] = numerical_gradient(loss_W, self.params[\"b2\"])\n",
        "\n",
        "          return grads\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDFrgQdGGCVZ"
      },
      "source": [
        "#例\n",
        "net = TwoLayerNet(input_size = 784, hidden_size = 100, output_size = 10)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R65RWfg6I7Yy",
        "outputId": "12915b5b-1aa1-4f5a-efaa-84041e78fdf6"
      },
      "source": [
        "net.params[\"W1\"].shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUqEpo4LI94p",
        "outputId": "46e530f9-7451-4579-90c5-d97b371fb428"
      },
      "source": [
        "net.params[\"b1\"].shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mK5_z3MJG3l",
        "outputId": "80735154-ed43-4c1c-895f-7f19f0b8c857"
      },
      "source": [
        "net.params[\"W2\"].shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44PEoq93JLui",
        "outputId": "39024dda-a517-47dc-810b-f5faf2f2801f"
      },
      "source": [
        "net.params[\"b2\"].shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYAFs3bJJmJQ"
      },
      "source": [
        "#適当に生成したデータで勾配を計算して出力させてみる\n",
        "\n",
        "x = np.random.rand(100, 784)\n",
        "t = np.random.rand(100, 10)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoIaa5R-KCvl"
      },
      "source": [
        "grads = net.numerical_gradient(x, t)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxr1dr2CKIBT",
        "outputId": "c1ee8999-4b15-446d-a4b7-ab02af49883b"
      },
      "source": [
        "grads[\"W1\"].shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNVWr01jMQT3",
        "outputId": "d23d9157-a63b-4f58-e8ff-5a99f2912c88"
      },
      "source": [
        "grads[\"b1\"].shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oEwttgkMTFs",
        "outputId": "c51aefdf-43b9-4ac6-a9a2-f3529c25efe3"
      },
      "source": [
        "grads[\"W2\"].shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRgZN6J6MYF2",
        "outputId": "749d782f-58b1-4c19-fb14-5e485a99ddbc"
      },
      "source": [
        "grads[\"b2\"].shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qdg4_ukMaVS"
      },
      "source": [
        "## 4.5.2 ミニバッチ学習の実装\n",
        "\n",
        "<br />\n",
        "\n",
        "NNの学習の実装は、前に説明したミニバッチ学習で行います。ミニバッチ学習とは、訓練データから無作為に一部のデータを取り出して、そのミニバッチを対象に勾配法でパラメータを実装する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hllk5JFGPbKA"
      },
      "source": [
        "# 実装\n",
        "\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = \\\n",
        "      load_mnist(normalize = True, one_hot_label = True)\n",
        "\n",
        "train_loss_list = []\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kL8zwxwQCFf"
      },
      "source": [
        "#hyper parameter\n",
        "iters_num = 10000#勾配法による更新の回数\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)#inputは画像の28 * 28 , outputは0から9までの10クラスを指す。\n",
        "\n",
        "# forの入れ子\n",
        "for i in range(iters_num):\n",
        "    #ミニバッチの取得\n",
        "    batch_mask = np.random.choice(train_size, batch_size)#trainからbatchのサイズを無作為に抽出\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    #勾配の計算\n",
        "\n",
        "    grad = network.gradient(x_batch, t_batch)#高速版を使用！\n",
        "\n",
        "    # parameterの更新\n",
        "    for key in (\"W1\", \"b1\", \"W2\", \"b2\"):\n",
        "          network.params[key] -= learning_rate * grad[key]#keyはパラメータであり、パラメータごとにfor loopで更新する\n",
        "\n",
        "\n",
        "    loss = network.loss(x_batch, t_batch)#for loopの回数だけ損失関数の値を計算する\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPrfwEMFUoKJ"
      },
      "source": [
        "## 4.5.3 テストデータで評価する\n",
        "\n",
        "<br />\n",
        "\n",
        "ミニバッチ学習によって、損失関数の値を減少させることができる。しかし、それはあくまで訓練データに対するフィッティングであって、現実のテストデータに対して同じ性能が出せるとは限らない。\n",
        "そもそも、NNの学習において重要なのは未知のデータに対しての予測能力を担保するための汎化能力を伸ばすことである。そのため、次の実装では学習の過程で定期的に訓練データとテストデータを対象に、1epochごとに認識精度を記録する。\n",
        "\n",
        "epochとは、学習において訓練データを全て使い切った時の回数に対応する。\n",
        "今回、10000個のデータを100個のミニバッチで学習するため、10000/100 = 100なので1エポックは100回である。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXFwouQ9Wbvf"
      },
      "source": [
        "# 正しい評価をするために実装を修正\n",
        "\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = \\\n",
        "      load_mnist(normalize = True, one_hot_label = True)\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKcm7IwfXFeJ"
      },
      "source": [
        "train_size = x_train.shape[0]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHYrsmTHXIma",
        "outputId": "7f76701e-e928-421a-e9eb-fe70b4f34ba2"
      },
      "source": [
        "#Hyper Parameter\n",
        "\n",
        "iters_num = 10000\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "#1epochあたりの繰り返し数\n",
        "iter_per_epoch = max(train_size/batch_size, 1)#エポックごとの繰り返し数の一般的な定義？\n",
        "\n",
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    # ミニバッチの取得\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    #勾配の計算\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "\n",
        "    for key in (\"W1\", \"b1\", \"W2\", \"b2\"):\n",
        "          network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
        "\n",
        "  \n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train acc, test acc | 0.10441666666666667, 0.1028\n",
            "train acc, test acc | 0.7872666666666667, 0.7912\n",
            "train acc, test acc | 0.8710666666666667, 0.8751\n",
            "train acc, test acc | 0.8956, 0.8972\n",
            "train acc, test acc | 0.9054833333333333, 0.9074\n",
            "train acc, test acc | 0.9114833333333333, 0.9126\n",
            "train acc, test acc | 0.9168333333333333, 0.9185\n",
            "train acc, test acc | 0.9224833333333333, 0.9235\n",
            "train acc, test acc | 0.9252833333333333, 0.9252\n",
            "train acc, test acc | 0.93, 0.9303\n",
            "train acc, test acc | 0.9322, 0.9327\n",
            "train acc, test acc | 0.9356, 0.9333\n",
            "train acc, test acc | 0.9377666666666666, 0.9373\n",
            "train acc, test acc | 0.9409666666666666, 0.9402\n",
            "train acc, test acc | 0.9424833333333333, 0.9411\n",
            "train acc, test acc | 0.9449166666666666, 0.9431\n",
            "train acc, test acc | 0.9466, 0.944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuatXkmma59r"
      },
      "source": [
        "### 4.6 まとめ\n",
        "\n",
        "<br />\n",
        "\n",
        "\n",
        "*　機械学習で使用するデータセットは、訓練データとテストデータに分けて使用する\n",
        "\n",
        "*　訓練データで学習を行い、学習したモデルの汎化能力をテストデータで評価する\n",
        "\n",
        "*   NNの学習は、損失関数を指標として損失関数の値が小さくなるように重みパラメータを更新する\n",
        "\n",
        "*   重みパラメータを更新する際には、重みパラメータの勾配を利用して、勾配方向に重みの値を更新する作業を繰り返す\n",
        "\n",
        "*   微小な値を与えた時の差分によって微分を行うことを数値微分という\n",
        "\n",
        "*   数値微分によって、重みパラメータの勾配を求めることができる。そして、この数値微分は時間がかかるが、誤差逆伝播法を用いるとより高速に勾配を求めることができる\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}